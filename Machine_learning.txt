Машинне навчання (англ. machine learning) — це підгалузь інформатики[1] 
(зокрема, м'яких[en] та гранульованих обчислень[en]), яка еволюціювала з 
дослідження розпізнавання образів та теорії обчислювального навчання[en] 
в галузі штучного інтелекту.[1] 1959 року Артур Семюель визначив машинне 
навчання як «Галузь досліджень, яка дає комп'ютерам здатність навчатися 
без того, щоби їх явно програмували».[2] Машинне навчання досліджує 
вивчення та побудову алгоритмів, які можуть навчатися з даних, і 
виконувати передбачувальний аналіз на них.[3] Такі алгоритми діють шляхом 
побудови моделі зі зразкового тренувального набору[en] вхідних 
спостережень, щоби здійснювати керовані даними прогнози або ухвалювати 
рішення, виражені як виходи,[4]:2 замість того, щоби суворо слідувати 
статичним програмним інструкціям.

Машинне навчання тісно пов'язане (і часто перетинається) з обчислювальною статистикою[en], дисципліною, яка також фокусується на прогнозуванні шляхом застосування комп'ютерів. Воно має тісні зв'язки з математичною оптимізацією, теорією матриць, лінійною алгеброю та копулами, які забезпечують цю галузь методами, теорією та прикладними областями. Машинне навчання застосовують в ряді обчислювальних задач, в яких розробка та програмування явних алгоритмів є нездійсненними. Приклади таких застосувань включають відфільтровування спаму[en], оптичне розпізнавання символів (ОРС),[5] пошукові системи[en] та комп'ютерний зір. Машинне навчання іноді з'єднують з добуванням даних,[6] де друга підгалузь фокусується більше на дослідницькому аналізі даних, і є відомою як навчання без учителя.[4]:vii[7]

В межах галузі аналізу даних машинне навчання є методом, який використовується для винаходження складних моделей та алгоритмів, які слугують прогнозуванню — в комерційному застосуванні це відоме як передбачувальна аналітика[en]. Ці аналітичні моделі дозволяють дослідникам, науковцям з даних, інженерам та аналітикам «виробляти надійні, повторювані рішення та результати» та розкривати «приховані розуміння» шляхом навчання з історичних співвідношень та тенденцій в даних.[8]

Том Мітчелл[en] запровадив широко цитоване формальніше визначення: «Кажуть, що комп'ютерна програма вчиться з досвіду E по відношенню до якогось класу задач T та міри продуктивності P, якщо її продуктивність у задачах з T, вимірювана за допомогою P, покращується з досвідом E.»[9] Це визначення є видатним тому, що воно визначає машинне навчання через фундаментально операційні[en], а не когнітивні, терміни, слідуючи таким чином пропозиції Алана Тюрінга в його праці «Обчислювальні машини та розум[en]», щоби питання «Чи можуть машини думати?» замінити питанням «Чи можуть машини робити те, що можемо робити ми (як істоти, які думають)?».[10]

Типи задач і завдань

Задачі машинного навчання, як правило, поділяють на три широкі категорії, в залежності від природи «сигналу», якого навчається система, або «зворотного зв'язку», доступного системі, яка навчається. Цими категоріями є:[11]

    Навчання з учителем (кероване навчання, англ. supervised learning): Комп'ютерові представляють приклади входів та їхніх бажаних виходів, задані «вчителем», і метою є навчання загального правила, яке відображає входи на виходи.
    Навчання без учителя (спонтанне навчання, англ. unsupervised learning): Алгоритмові навчання не дається міток, залишаючи його самому знаходити структуру в своєму вході. Навчання без учителя може бути метою саме по собі (виявлення прихованих закономірностей у даних), або засобом досягнення мети (навчання ознак).
    Навчання з підкріпленням (англ. reinforcement learning): Комп'ютерна програма взаємодіє з динамічним середовищем, у якому вона повинна виконувати певну мету (таку як водіння автівки), без учителя, який явно казав би їй, чи підійшла вона близько до мети. Іншим прикладом є навчання грі через гру із суперником.[4]:3

Між керованим та спонтанним навчанням є напівавтоматичне навчання (англ. semi-supervised learning), в якому вчитель дає неповний тренувальний сигнал: тренувальний набір, в якому відсутні деякі (часто численні) цільові виходи. Окремим випадком цього принципу є трансдукція[en] (англ. transduction), коли під час навчання відомий повний набір випадків задачі, крім частини цілей, яких бракує.
Метод опорних векторів є класифікатором, який поділяє свій вхідний простір на дві області, розділені лінійною межею. Тут він навчається розрізнювати чорні та білі круги.

Серед інших задач машинного навчання навчання навчатися[en] навчається свого власного індуктивного упередження[en] на основі попереднього досвіду. Еволюційне навчання[en] (англ. developmental learning), розроблене для навчання роботів[en], породжує свої власні послідовності навчальних ситуацій (також звані навчальним планом, англ. curriculum), щоби накопичувально отримувати репертуари нових навичок шляхом автономного само-дослідження та соціальної взаємодії з вчителями-людьми, і застосування провідних механізмів, таких як активне навчання, дозрівання, рухова синергія та імітація.

Інша класифікація завдань машинного навчання виникає при розгляді бажаного виходу системи з машинним навчанням:[4]:3

    У класифікації (англ. classification) входи поділяються на два або більше класів, і система-учень мусить породити модель, яка відносить небачені входи до одного або більше (багатоміткова класифікація[en]) з цих класів. Це, як правило, намагаються розв'язувати керованим чином. Прикладом класифікації є фільтри спаму, в яких входами є повідомлення електронної пошти (або чогось іншого), а класами є «спам» та «не спам».
    У регресії (англ. regression), також керованій задачі, виходи є безперервними, а не дискретними.
    У кластеруванні (англ. clustering) набір входів повинно бути поділено на групи. На відміну від класифікації, групи не відомі заздалегідь, що зазвичай робить це завданням для спонтанного навчання.
    Оцінка густини знаходить розподіл входів у деякому просторі.
    Зниження розмірності[en] спрощує входи шляхом відображення їх на простір меншої розмірності. Пов'язаною задачею є тематичне моделювання[en], в якому програмі надається перелік документів людською мовою, і дається завдання з'ясувати, які документи охоплюють подібні теми.
Історія та відношення до інших областей

Детальніші відомості з цієї теми Ви можете знайти в статті Хронологія розвитку машинного навчання[en].

Як наукове прагнення, машинне навчання виросло з розшуків штучного інтелекту. Вже ранніми днями ШІ як академічної дисципліни деякі дослідники зацікавилися тим, щоби машини вчилися з даних. Вони намагалися наблизитися до розв'язання цієї задачі різними символьними методами, а також тим, що згодом було названо «нейронними мережами»; це були здебільшого перцептрони та інші моделі, які згодом виявилися повторними винаходами узагальнених лінійних моделей[en] статистики. Застосовувалося також і ймовірнісне міркування, особливо в автоматизованій медичній діагностиці.[11]:488

Проте зростання акценту на логічному, основаному на знаннях підході[en] викликало розрив між ШІ та машинним навчанням. Ймовірнісні системи страждали на теоретичні та практичні проблеми збирання та представлення даних.[11]:488 Близько 1980 року прийшли експертні системи, щоби домінувати над ШІ, а статистика була в немилості.[12] Робота над навчанням на основі символів/знань дійсно продовжувалася в межах ШІ, ведучи до індуктивного логічного програмування[en], але більш статистична лінія досліджень була тепер поза межами області справжнього ШІ, в розпізнаванні образів та інформаційному пошуку.[11]:708–710; 755 Приблизно в цей же час ШІ та інформатикою було облишено дослідження нейронних мереж. Цю лінію також було продовжено за межами області ШІ/інформатики, як «конективізм[en]», дослідниками з інших дисциплін, включно з Хопфілдом, Румельхартом[en] та Хінтоном[en]. Їхній головний успіх прийшов у середині 1980-х років із повторним винайденням зворотного поширення.[11]:25

Машинне навчання, реорганізоване як окрема область, почало бурхливо розвиватися в 1990-х роках. Ця область змінила свої цілі з досягання штучного інтелекту на розв'язання розв'язних задач практичного характеру. Вона змістила фокус із символьних підходів, успадкованих нею від ШІ, в бік методів та моделей, позичених зі статистики та теорії ймовірності.[12] Вона також виграла від збільшуваної доступності оцифрованої інформації та можливості розповсюджувати її через Інтернет.

Машинне навчання та добування даних часто використовують одні й ті ж методи, і значно перекриваються. Їх можна грубо розрізнити наступним чином:

    Машинне навчання фокусується на передбаченні на основі відомих властивостей, вивчених з тренувальних даних.
    Добування даних фокусується на відкритті невідомих (раніше) властивостей даних. Воно є кроком аналізу з виявлення знань у базах даних.

Ці дві області перекриваються у багатьох відношеннях: добування даних використовує багато методів машинного навчання, але часто з дещо іншою метою. З іншого боку, машинне навчання також застосовує методи добування даних як «навчання без учителя», або як крок попередньої обробки для покращення точності механізму навчання. Велика частина плутанини між цими двома дослідницькими спільнотами (які часто мають окремі конференції та окремі журнали, з ECML PKDD[en] як основним винятком) виходить з основних припущень, з якими вони працюють: у машинному навчанні продуктивність зазвичай оцінюється по відношенню до здатності відтворювати відоме знання, тоді як у виявленні знань та добуванні даних (англ. Knowledge Discovery and Data Mining, KDD) ключовою задачею є виявлення не відомого раніше знання. При оцінці по відношенню до відомих знань неінформований (некерований) метод легко програватиме керованим методам, тоді як у типовій задачі KDD керовані методи застосовуватися не можуть в силу відсутності тренувальних даних.

Машинне навчання також має тісні зв'язки з оптимізацією: багато задач навчання формулюються як мінімізація деякої функції втрат на тренувальному наборі прикладів. Функції втрат виражають розбіжність між передбаченнями тренованої моделі та дійсними зразками задачі (наприклад, у класифікації потрібно призначати мітки зразкам, і моделі тренуються правильно передбачати попередньо призначені мітки набору прикладів). Різниця між цими двома областями виникає з мети узагальнення: в той час як алгоритми оптимізації можуть мінімізувати втрати на тренувальному наборі, машинне навчення зосереджене на мінімізації втрат на небачених зразках.[13]
Відношення до статистики

Машинне навчання та статистика є тісно пов'язаними областями. Згідно Майкла І. Джордана[en], ідеї машинного навчання, від методологічних принципів до теоретичних інструментів, мали довгу передісторію в статистиці.[14] Він також запропонував термін «наука про дані» для позначення загальної області.[14]

Лео Брейман[en] виділив дві парадигми статистичного моделювання: модель даних, та алгоритмічну модель,[15] де «алгоритмічна модель» означає більш-менш алгоритми машинного навчання, такі як випадковий ліс.

Деякі фахівці зі статистики запозичили методи з машинного навчання, ведучи до об'єднаної області, яку вони називають статистичним навчанням (англ. statistical learning).[16]
Теорія

Детальніші відомості з цієї теми Ви можете знайти в статті Теорія обчислювального навчання[en].

Основна мета системи, яка навчається, — це робити узагальнення зі свого досвіду.[17][18] Узагальнення в цьому контексті є здатністю машини, яка вчиться, працювати точно на нових, не бачених прикладах/задачах після отримання досвіду навчального набору даних. Тренувальні приклади походять з якогось загалом невідомого розподілу ймовірності (який вважається представницьким для простору випадків), і система, яка вчиться, має будувати загальну модель цього простору, яка дозволяє їй виробляти достатньо точні передбачення в нових випадках.

Обчислювальний аналіз алгоритмів машинного навчання та їхньої продуктивності є галуззю теоретичної інформатики, відомої як теорія обчислювального навчання[en] (англ. computational learning theory). Оскільки тренувальні набори є скінченними, а майбутнє є непевним, теорія навчання зазвичай не дає гарантій продуктивності алгоритмів. Натомість доволі поширеними є ймовірнісні рамки продуктивності. Одним зі шляхів кількісної оцінки похибки узагальнення є компроміс зсуву та дисперсії.

Те, наскільки добре модель, натренована наявними прикладами, передбачує виходи для невідомих випадків, називається узагальненням. Щоб узагальнення було найкращим, складність його гіпотези повинна відповідати складності функції, яка лежить в основі даних. Якщо гіпотеза є менш складною за цю функцію, то ми недовчилися. Тоді ми підвищуємо складність, і похибка тренування знижується. Але якщо наша гіпотеза є занадто складною, то ми перевчилися. Після цього ми повинні знайти гіпотезу, яка має мінімальну похибку тренування.[19]

На додачу до рамок продуктивності, теоретики обчислювального навчання досліджують часову складність та здійсненність навчання. В теорії обчислювального навчання обчислення вважається здійсненним, якщо його може бути виконано за поліноміальний час[en]. Є два види результатів часової складності[en]. Позитивні результати показують, що певного класу функцій може бути навчено за поліноміальний час. Негативні результати показують, що певних класів не може бути навчено за поліноміальний час.

Існує багато схожостей між теорією машинного навчання та статистичним виведенням, хоча вони використовують відмінні терміні.
